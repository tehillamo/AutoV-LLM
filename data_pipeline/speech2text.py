from pydub import AudioSegment
import os
from argparse import ArgumentParser
import csv
import whisper
import pandas as pd

class Speech2Text:
    def __init__(self, input_path, model):
        """
        Initializes a new instance of the class.

        Args:
            input_path (str): The path to the input file.
            model (str): The model to be used.

        Returns:
            None
        """
        self.path = input_path
        self.model = model


    def _cut_audio(self, timestamps, audio):
        """
        Cuts an audio into segments based on the given timestamps.

        Parameters:
            timestamps (List[int]): A list of integers representing the timestamps in milliseconds.
            audio (AudioSegment): The audio to be cut.

        Returns:
            List[AudioSegment]: A list of AudioSegments representing the segmented audio.
        """
        audio_result = []
        for i, time in enumerate(timestamps):
            if i == len(timestamps) - 1:
                audio_result.append(audio[time:])
                break
            t1 = time
            t2 = timestamps[i+1]
            audio_result.append(audio[t1:t2])
        return audio_result

    def _read_timestamps(self, path):
        """
        Read timestamps from a file.

        Args:
            path (str): The path to the directory containing the timestamps file.

        Returns:
            list: A list of integers representing the timestamps.
        """
        with open(os.path.join(path, "timestamps.txt"), "r") as f:
            timestamps = f.readlines()
        return [int(x) for x in timestamps[0].split(",")]

    def _split_audio(self, uuid, path):
        """
        Generates audio segments by splitting a given audio file based on timestamps.

        Args:
            uuid (str): The unique identifier of the audio file.
            path (str): The path to the ressource directory.

        Returns:
            List[AudioSegment]: A list of audio segments generated by splitting the input audio file.
        """
        audio = AudioSegment.from_file(os.path.join(path, uuid, "audio.mp3"))
        audios = self._cut_audio(self._read_timestamps(os.path.join(path, uuid)), audio)
        return audios

    def _save_audios_to_files(self, audios, path):
        """
        Save audios to files.

        Args:
            audios (List[AudioSegment]): A list of audio objects.
            path (str): The path where the audio files will be saved.

        Returns:
            None
        """
        for i, a in enumerate(audios):
            a.export(os.path.join(path, f'{i}.mp3'), format="mp3")

    def transcribe(self):       
        """
        Transcribes audio files located in the specified path.
        
        :return: A pandas DataFrame containing the transcribed text for each audio file.
        """
        # find all uuids in ressource path
        uuids = os.listdir(self.path)
        uuids.remove('.gitkeep')
        print('Splitting audio...')
        for uuid in uuids:
            # split all audios into trial recordings
            print(uuid)
            audios = self._split_audio(uuid, self.path)
            self._save_audios_to_files(audios, os.path.join(self.path, uuid))

        print('Transcribing audio...')

        uuids = os.listdir(self.path)
        uuids.remove('.gitkeep')

        df = pd.DataFrame(columns=['uuid', 'trial_number', 'transcribed_text'])
        # For each uuid transcribe all trial audio recordings
        for uuid in uuids:
            print(uuid)
            paths = self._get_all_cutted_audios(os.path.join(self.path, uuid))
            transcribed = self._transcribe_audios(paths, self.model)
            for i, text in enumerate(transcribed):
                new_row = {
                    'uuid': str(uuid),
                    'trial_number': int(i),
                    'transcribed_text': str(text).strip()
                }
                new_row_df = pd.DataFrame(new_row, index=[0])
                df = pd.concat([df, new_row_df], ignore_index=True)
        return df
        
    def _get_all_cutted_audios(self, path):
        """
        Retrieves a list of all the cut audio files in the specified directory.

        Parameters:
            path (str): The path to the directory containing the audio files.

        Returns:
            list: A list of file paths for all the cut audio files in the directory.
        """
        files = []
        for file in os.listdir(path):
            if file.endswith(".mp3") and not file.startswith("audio"):
                files.append(os.path.join(path, file))
        return files

    def _transcribe_audios(self, paths, model):
        """
        Transcribes a list of audio files using the Whisper library.

        Args:
            paths (List[str]): A list of file paths to audio files.
            model (str): The model to use for transcribing

        Returns:
            List[str]: A list of transcribed text for each audio file.
        """
        # parameter which model to use
        model = whisper.load_model(model)
        transcribed = []
        for path in paths:
            res = ''
            # if files are too small then we get an error. This is a workaround
            try:
                res = model.transcribe(os.path.join(path), fp16=False)
                res = res['text']
            except:
                print('File is too small to transcribe (path: ' + path + ')')
            transcribed.append(res)
        return transcribed

